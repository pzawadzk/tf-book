{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/0c/d01aa759fdc501a58f431eb594a17495f15b88da142ce14b5845662c13f3/pip-20.0.2-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.4MB 20.9MB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 10.0.1\n",
      "    Uninstalling pip-10.0.1:\n",
      "      Successfully uninstalled pip-10.0.1\n",
      "Successfully installed pip-20.0.2\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-45.1.0-py3-none-any.whl (583 kB)\n",
      "\u001b[K     |████████████████████████████████| 583 kB 5.8 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: setuptools\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 41.6.0\n",
      "    Uninstalling setuptools-41.6.0:\n",
      "      Successfully uninstalled setuptools-41.6.0\n",
      "Successfully installed setuptools-45.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip         # pip 19.0 or higher is required for TF 2\n",
    "!pip install --upgrade setuptools  # Otherwise you'll get annoying warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu\n",
      "  Downloading tensorflow_gpu-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 421.8 MB 2.1 kB/s  eta 0:00:01    |██████▍                         | 83.6 MB 57.4 MB/s eta 0:00:06     |███████████▎                    | 148.8 MB 65.2 MB/s eta 0:00:05     |██████████████████▋             | 244.8 MB 57.2 MB/s eta 0:00:04     |████████████████████████▏       | 319.1 MB 61.5 MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from tensorflow-gpu) (0.1.8)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from tensorflow-gpu) (0.8.1)\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
      "  Downloading tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
      "\u001b[K     |████████████████████████████████| 448 kB 31.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from tensorflow-gpu) (1.0.8)\n",
      "Collecting six>=1.12.0\n",
      "  Downloading six-1.14.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from tensorflow-gpu) (0.31.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from tensorflow-gpu) (1.17.4)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from tensorflow-gpu) (3.8.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from tensorflow-gpu) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.1.0.tar.gz (69 kB)\n",
      "\u001b[K     |████████████████████████████████| 69 kB 11.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from tensorflow-gpu) (1.16.0)\n",
      "Collecting tensorboard<2.2.0,>=2.1.0\n",
      "  Downloading tensorboard-2.1.0-py3-none-any.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 64.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy==1.4.1; python_version >= \"3\"\n",
      "  Using cached scipy-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (26.1 MB)\n",
      "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from tensorflow-gpu) (0.7.1)\n",
      "Collecting gast==0.2.2\n",
      "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from protobuf>=3.8.0->tensorflow-gpu) (45.1.0)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.22.0-py2.py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.1.1)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.11.0-py2.py3-none-any.whl (76 kB)\n",
      "\u001b[K     |████████████████████████████████| 76 kB 1.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.14.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.23)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2019.9.11)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.6)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.0.0-py3-none-any.whl (10 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 53.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.4.2)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 41.8 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: opt-einsum, gast\n",
      "  Building wheel for opt-einsum (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for opt-einsum: filename=opt_einsum-3.1.0-py3-none-any.whl size=60860 sha256=6a007ec7e7848358b2e619f9690f598aecdea72a1f6b2b8131b0597085e23acd\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/1f/6f/14/e0f4f6bceec756bbab45c392c4d5429a684b14d849464ebfbf\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=6587 sha256=5e82168b5958362ca7966374ed4de43c864acf24728a015e840a344f7d5a24a1\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/19/a7/b9/0740c7a3a7d1d348f04823339274b90de25fbcd217b2ee1fbe\n",
      "Successfully built opt-einsum gast\n",
      "\u001b[31mERROR: tensorflow 1.14.0 has requirement tensorboard<1.15.0,>=1.14.0, but you'll have tensorboard 2.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 1.14.0 has requirement tensorflow-estimator<1.15.0rc0,>=1.14.0rc0, but you'll have tensorflow-estimator 2.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorboard 2.1.0 has requirement grpcio>=1.24.3, but you'll have grpcio 1.16.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tensorflow-estimator, six, opt-einsum, requests, cachetools, pyasn1-modules, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard, scipy, gast, tensorflow-gpu\n",
      "\u001b[33m  WARNING: The script google-oauthlib-tool is installed in '/home/ec2-user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script tensorboard is installed in '/home/ec2-user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts estimator_ckpt_converter, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/home/ec2-user/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed cachetools-4.0.0 gast-0.2.2 google-auth-1.11.0 google-auth-oauthlib-0.4.1 oauthlib-3.1.0 opt-einsum-3.1.0 pyasn1-modules-0.2.8 requests-2.22.0 requests-oauthlib-1.3.0 scipy-1.4.1 six-1.14.0 tensorboard-2.1.0 tensorflow-estimator-2.1.0 tensorflow-gpu-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --user --upgrade tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series(batch_size, n_steps):\n",
    "    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n",
    "    time = np.linspace(0, 1, n_steps)\n",
    "    series = 0.5 * np.sin((time - offsets1) * (freq1 * 10 + 10))  #   wave 1\n",
    "    series += 0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20)) # + wave 2\n",
    "    series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5)   # + noise\n",
    "    return series[..., np.newaxis].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 50\n",
    "series = generate_time_series(10000, n_steps + 1)\n",
    "X_train, y_train = series[:7000, :n_steps], series[:7000, -1]\n",
    "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
    "X_test, y_test = series[9000:, :n_steps], series[9000:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "## Use the last value as baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020744413"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = X_valid[:, -1]\n",
    "result = keras.losses.mean_squared_error(y_valid, y_pred)\n",
    "np.mean(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 1s 135us/sample - loss: 0.0753 - val_loss: 0.0323\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 1s 86us/sample - loss: 0.0227 - val_loss: 0.0165\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 1s 85us/sample - loss: 0.0132 - val_loss: 0.0108\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 1s 85us/sample - loss: 0.0095 - val_loss: 0.0084\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 1s 86us/sample - loss: 0.0078 - val_loss: 0.0072\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 1s 87us/sample - loss: 0.0068 - val_loss: 0.0065\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 1s 88us/sample - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 1s 98us/sample - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 1s 97us/sample - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 1s 97us/sample - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 1s 98us/sample - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 1s 101us/sample - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 1s 88us/sample - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 1s 86us/sample - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 1s 87us/sample - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 1s 86us/sample - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 1s 86us/sample - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 1s 86us/sample - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 1s 86us/sample - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 1s 86us/sample - loss: 0.0037 - val_loss: 0.0037\n"
     ]
    }
   ],
   "source": [
    "lin_reg = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[50, 1]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "lin_reg.compile(loss='mean_squared_error', optimizer='adam')\n",
    "history = lin_reg.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "valid_error = lin_reg.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003679195249453187"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 8s 1ms/sample - loss: 0.1430 - val_loss: 0.1422\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 7s 940us/sample - loss: 0.1400 - val_loss: 0.1414\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 7s 936us/sample - loss: 0.1399 - val_loss: 0.1430\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 7s 931us/sample - loss: 0.1399 - val_loss: 0.1400\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 7s 935us/sample - loss: 0.1393 - val_loss: 0.1396\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 7s 946us/sample - loss: 0.1392 - val_loss: 0.1399\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 7s 946us/sample - loss: 0.1397 - val_loss: 0.1416\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 7s 944us/sample - loss: 0.1403 - val_loss: 0.1413\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 7s 944us/sample - loss: 0.1405 - val_loss: 0.1401\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 7s 945us/sample - loss: 0.1402 - val_loss: 0.1433\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 7s 944us/sample - loss: 0.1401 - val_loss: 0.1397\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 7s 945us/sample - loss: 0.1396 - val_loss: 0.1400\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 7s 938us/sample - loss: 0.1393 - val_loss: 0.1396\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 7s 938us/sample - loss: 0.1398 - val_loss: 0.1400\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 7s 941us/sample - loss: 0.1397 - val_loss: 0.1400\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 7s 948us/sample - loss: 0.1391 - val_loss: 0.1408\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 7s 947us/sample - loss: 0.1400 - val_loss: 0.1399\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 7s 938us/sample - loss: 0.1388 - val_loss: 0.1413\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 7s 940us/sample - loss: 0.1392 - val_loss: 0.1402\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 7s 941us/sample - loss: 0.1392 - val_loss: 0.1428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f69c0775748>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "  keras.layers.SimpleRNN(1, input_shape=[None, 1])\n",
    "])\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_rnn = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=(None, 1)),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(1)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20*20 + 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_6 (SimpleRNN)     (None, None, 20)          440       \n",
      "_________________________________________________________________\n",
      "simple_rnn_7 (SimpleRNN)     (None, None, 20)          820       \n",
      "_________________________________________________________________\n",
      "simple_rnn_8 (SimpleRNN)     (None, 1)                 22        \n",
      "=================================================================\n",
      "Total params: 1,282\n",
      "Trainable params: 1,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "deep_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 21s 3ms/sample - loss: 0.0180 - val_loss: 0.0044\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 18s 3ms/sample - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 18s 3ms/sample - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 18s 3ms/sample - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 18s 3ms/sample - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 18s 3ms/sample - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 18s 3ms/sample - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 19s 3ms/sample - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 19s 3ms/sample - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 18s 3ms/sample - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 18s 3ms/sample - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 18s 3ms/sample - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 18s 3ms/sample - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 18s 3ms/sample - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 18s 3ms/sample - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 18s 3ms/sample - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 18s 3ms/sample - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 19s 3ms/sample - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 18s 3ms/sample - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 18s 3ms/sample - loss: 0.0028 - val_loss: 0.0029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f697fc6c048>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_rnn.compile(optimizer='adam', loss='mean_squared_error')\n",
    "deep_rnn.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 15s 2ms/sample - loss: 0.0223 - val_loss: 0.0050\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 13s 2ms/sample - loss: 0.0029 - val_loss: 0.0030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f697d7128d0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_rnn_dense = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=(None, 1)),\n",
    "    keras.layers.SimpleRNN(20),\n",
    "    keras.layers.Dense(1)]\n",
    ")\n",
    "deep_rnn_dense.compile(optimizer='adam', loss='mean_squared_error')\n",
    "deep_rnn_dense.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting N steps ahead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict N times one step ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = generate_time_series(1, n_steps + 10)\n",
    "X_new, Y_new = series[:, :n_steps], series[:, n_steps:]\n",
    "X = X_new\n",
    "for step_ahead in range(10):\n",
    "    y_pred_one = deep_rnn_dense.predict(X[:, step_ahead:])[:, np.newaxis, :]\n",
    "    X = np.concatenate([X, y_pred_one], axis=1)\n",
    "\n",
    "Y_pred = X[:, n_steps:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00803183"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = keras.losses.mean_squared_error(Y_new, Y_pred)\n",
    "np.mean(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = X_new.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f697a364668>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(n_steps), X_new.reshape(-1))\n",
    "plt.plot(np.arange(n_steps, n_steps+10), Y_new.reshape(-1))\n",
    "plt.plot(np.arange(n_steps, n_steps+10), Y_pred.reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict N steps at once with sequence-to-vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = generate_time_series(10000, n_steps + 10)\n",
    "X_train, Y_train = series[:7000, :n_steps], series[:7000, -10:, 0]\n",
    "X_valid, Y_valid = series[7000:9000, :n_steps], series[7000:9000, -10:, 0]\n",
    "X_test, Y_test = series[9000:, :n_steps], series[9000:, -10:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "7000/7000 [==============================] - 19s 3ms/sample - loss: 0.0662 - val_loss: 0.0328\n",
      "Epoch 2/10\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0264 - val_loss: 0.0207\n",
      "Epoch 3/10\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0187 - val_loss: 0.0165\n",
      "Epoch 4/10\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0165 - val_loss: 0.0159\n",
      "Epoch 5/10\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0147 - val_loss: 0.0166\n",
      "Epoch 6/10\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0142 - val_loss: 0.0150\n",
      "Epoch 7/10\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0140 - val_loss: 0.0127\n",
      "Epoch 8/10\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0132 - val_loss: 0.0129\n",
      "Epoch 9/10\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0128 - val_loss: 0.0127\n",
      "Epoch 10/10\n",
      "7000/7000 [==============================] - 12s 2ms/sample - loss: 0.0131 - val_loss: 0.0127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9aa434bba8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_seq_to_vec = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model_seq_to_vec.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model_seq_to_vec.fit(X_train, Y_train, epochs=10, validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict N steps at once with sequence-to-sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.empty((10000, n_steps, 10)) # each target is a sequence of 10D vectors\n",
    "for step_ahead in range(1, 10 + 1):\n",
    "    Y[:, :, step_ahead - 1] = series[:, step_ahead:step_ahead + n_steps, 0]\n",
    "Y_train = Y[:7000]\n",
    "Y_valid = Y[7000:9000]\n",
    "Y_test = Y[9000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 50, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_seq_to_seq = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_time_step_mse(Y_true, Y_pred):\n",
    "    return keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_seq_to_seq.compile(loss=\"mse\", optimizer=optimizer, metrics=[last_time_step_mse])\n",
    "model_seq_to_seq.fit(X_train, Y_train, epochs=10, validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_seq_to_seq_lstm = keras.models.Sequential([\n",
    "    keras.layers.LSTM(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.LSTM(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "  32/7000 [..............................] - ETA: 14:59"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " [_Derived_]  Fail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[sequential/lstm/StatefulPartitionedCall]] [Op:__inference_distributed_function_5866]\n\nFunction call stack:\ndistributed_function -> distributed_function -> distributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-bf243e17a682>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_seq_to_seq_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mse\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlast_time_step_mse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_seq_to_seq_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m:  [_Derived_]  Fail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[sequential/lstm/StatefulPartitionedCall]] [Op:__inference_distributed_function_5866]\n\nFunction call stack:\ndistributed_function -> distributed_function -> distributed_function\n"
     ]
    }
   ],
   "source": [
    "model_seq_to_seq_lstm.compile(loss=\"mse\", optimizer=optimizer, metrics=[last_time_step_mse])\n",
    "model_seq_to_seq_lstm.fit(X_train, Y_train, epochs=10, validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
