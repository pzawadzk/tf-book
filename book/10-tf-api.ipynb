{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (1.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from pydot) (2.2.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (0.13.2)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MedInc',\n",
       " 'HouseAge',\n",
       " 'AveRooms',\n",
       " 'AveBedrms',\n",
       " 'Population',\n",
       " 'AveOccup',\n",
       " 'Latitude',\n",
       " 'Longitude']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block\n",
      "        - HouseAge      median house age in block\n",
      "        - AveRooms      average number of rooms\n",
      "        - AveBedrms     average number of bedrooms\n",
      "        - Population    block population\n",
      "        - AveOccup      average house occupancy\n",
      "        - Latitude      house block latitude\n",
      "        - Longitude     house block longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "http://lib.stat.cmu.edu/datasets/\n",
      "\n",
      "The target variable is the median house value for California districts.\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(housing.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 11610 samples, validate on 3870 samples\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.8534 - val_loss: 0.6072\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.5271 - val_loss: 0.4795\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4681 - val_loss: 0.4383\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 0.4470 - val_loss: 0.4187\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4389 - val_loss: 0.4122\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4358 - val_loss: 0.4107\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4312 - val_loss: 0.4055\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4301 - val_loss: 0.4084\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4268 - val_loss: 0.4255\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4244 - val_loss: 0.4216\n",
      "5160/5160 [==============================] - 0s 15us/sample - loss: 0.4174\n"
     ]
    }
   ],
   "source": [
    "seq_model = keras.Sequential([\n",
    "    keras.layers.Dense(10, input_shape=[8,], activation='relu'),\n",
    "   # keras.layers.Dense(10, activation='relu'),\n",
    "    keras.layers.Dense(1)])\n",
    "\n",
    "seq_model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "history = seq_model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
    "\n",
    "mse_test = seq_model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3] # pretend these are new instances\n",
    "y_pred = seq_model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(seq_model, \"my_seq_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                90        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hiden1 = keras.layers.Dense(30, activation='relu')(input_)\n",
    "hiden2 = keras.layers.Dense(30, activation='relu')(hiden1)\n",
    "output = keras.layers.Dense(1)(hiden2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_model = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.8020 - val_loss: 5.4864\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4398 - val_loss: 2.4588\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4155 - val_loss: 3.4717\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.4011 - val_loss: 0.6084\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3750 - val_loss: 0.5194\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3681 - val_loss: 0.3482\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.3592 - val_loss: 0.3980\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3559 - val_loss: 0.4221\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3505 - val_loss: 0.3519\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.3481 - val_loss: 0.4908\n"
     ]
    }
   ],
   "source": [
    "func_model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "history = func_model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                270       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 1,231\n",
      "Trainable params: 1,231\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "func_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_A, X_train_B = X_train[:, :4], X_train[:, 4:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :4], X_valid[:, 4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[4])\n",
    "input_B = keras.layers.Input(shape=[4])\n",
    "\n",
    "hiden1 = keras.layers.Dense(30, activation='relu')(input_A)\n",
    "hiden2 = keras.layers.Dense(30, activation='relu')(hiden1)\n",
    "\n",
    "concat = keras.layers.concatenate([input_B, hiden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "func_2_model = keras.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 2.0575 - val_loss: 0.9336\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.7718 - val_loss: 0.7184\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.6773 - val_loss: 1.0828\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.6372 - val_loss: 1.2943\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.6111 - val_loss: 1.0126\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.5864 - val_loss: 1.2052\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.5715 - val_loss: 0.9604\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.5568 - val_loss: 0.9485\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.5448 - val_loss: 1.0721\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.5352 - val_loss: 1.2112\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.5295 - val_loss: 0.9747\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.5226 - val_loss: 0.8304\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.5156 - val_loss: 0.9931\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.5123 - val_loss: 0.7995\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.5076 - val_loss: 0.8093\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.5033 - val_loss: 0.9529\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4999 - val_loss: 1.0749\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4987 - val_loss: 0.6067\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4955 - val_loss: 0.6254\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.4916 - val_loss: 0.9049\n"
     ]
    }
   ],
   "source": [
    "func_2_model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = func_2_model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 30)           150         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 30)           930         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 34)           0           input_7[0][0]                    \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            35          concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,115\n",
      "Trainable params: 1,115\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "func_2_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subclassing API to Build Dynamic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs) # handles standard args (e.g., name)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        return main_output\n",
    "\n",
    "subclass_model= WideAndDeepModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 1.8698 - val_loss: 0.9041\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.7827 - val_loss: 0.6926\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.6751 - val_loss: 0.6251\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.6159 - val_loss: 0.5852\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.5754 - val_loss: 0.5357\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.5448 - val_loss: 0.5078\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.5211 - val_loss: 0.4866\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.5018 - val_loss: 0.4658\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4863 - val_loss: 0.4513\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4728 - val_loss: 0.4356\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4615 - val_loss: 0.4245\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4540 - val_loss: 0.4153\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4485 - val_loss: 0.4097\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4444 - val_loss: 0.4106\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4408 - val_loss: 0.4145\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4382 - val_loss: 0.4015\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4355 - val_loss: 0.4075\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.4332 - val_loss: 0.4107\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4313 - val_loss: 0.4058\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 0.4291 - val_loss: 0.3947\n"
     ]
    }
   ],
   "source": [
    "subclass_model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = subclass_model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
