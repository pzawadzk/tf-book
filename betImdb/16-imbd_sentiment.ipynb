{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: \n",
    "\n",
    "- Finish preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_hub\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/0e/a91780d07592b1abf9c91344ce459472cc19db3b67fdf3a61dca6ebb2f5c/tensorflow_hub-0.7.0-py2.py3-none-any.whl (89kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 697kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.4.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow_hub) (3.8.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow_hub) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow_hub) (1.16.4)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from protobuf>=3.4.0->tensorflow_hub) (41.6.0)\n",
      "Installing collected packages: tensorflow-hub\n",
      "Successfully installed tensorflow-hub-0.7.0\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-datasets\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/b9/74c219b0310b3df0ac60c4948c4191b9377b6b746615b176819533096fb5/tensorflow_datasets-2.0.0-py3-none-any.whl (3.1MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1MB 4.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-datasets) (1.11.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-datasets) (2.20.0)\n",
      "Requirement already satisfied: wrapt in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-datasets) (1.11.2)\n",
      "Collecting tensorflow-metadata\n",
      "  Downloading https://files.pythonhosted.org/packages/3c/aa/c4c3c9339fbe9d46edd390789d7033b4fa89e9f566d5723576dfdd3ed18e/tensorflow_metadata-0.21.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-datasets) (1.16.4)\n",
      "Requirement already satisfied: termcolor in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-datasets) (1.1.0)\n",
      "Collecting dill\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/11/345f3173809cea7f1a193bfbf02403fff250a3360e0e118a1630985e547d/dill-0.3.1.1.tar.gz (151kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 48.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/55/fd9170ba08a1a64a18a7f8a18f088037316f2a41be04d2fe6ece5a653e8f/tqdm-4.43.0-py2.py3-none-any.whl (59kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 13.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-datasets) (0.8.1)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-datasets) (18.1.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-datasets) (3.8.0)\n",
      "Collecting future\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
      "\u001b[K     |████████████████████████████████| 829kB 45.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting promise\n",
      "  Downloading https://files.pythonhosted.org/packages/cf/9c/fb5d48abfe5d791cd496e4242ebcf87a4bb2e0c3dcd6e0ae68c11426a528/promise-2.3.tar.gz\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests>=2.19.0->tensorflow-datasets) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests>=2.19.0->tensorflow-datasets) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests>=2.19.0->tensorflow-datasets) (2019.9.11)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests>=2.19.0->tensorflow-datasets) (1.23)\n",
      "Collecting googleapis-common-protos\n",
      "  Downloading https://files.pythonhosted.org/packages/05/46/168fd780f594a4d61122f7f3dc0561686084319ad73b4febbf02ae8b32cf/googleapis-common-protos-1.51.0.tar.gz\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow-datasets) (41.6.0)\n",
      "Building wheels for collected packages: dill, future, promise, googleapis-common-protos\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dill: filename=dill-0.3.1.1-cp36-none-any.whl size=77454 sha256=7240176233640a6572b4c9e614a4c2a5eed1d72e69fedf5cfb1383421a7766c6\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/59/b1/91/f02e76c732915c4015ab4010f3015469866c1eb9b14058d8e7\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-cp36-none-any.whl size=491095 sha256=63b1a8c1d1d14185459f125849755be685cfe7b8c4b03b1fe2f8b58aa80700fd\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-cp36-none-any.whl size=20685 sha256=be2be8db0d6e578ad9cd01d59e25a4c1e91c39f789377da15cbc50ae88602b1f\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/19/49/34/c3c1e78bcb954c49e5ec0d31784fe63d14d427f316b12fbde9\n",
      "  Building wheel for googleapis-common-protos (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for googleapis-common-protos: filename=googleapis_common_protos-1.51.0-cp36-none-any.whl size=73426 sha256=9c5f528ac345111fab2ea832fee07f772fbd3c7936603d1c825d186fc4ba0fbb\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/2c/f9/7f/6eb87e636072bf467e25348bbeb96849333e6a080dca78f706\n",
      "Successfully built dill future promise googleapis-common-protos\n",
      "Installing collected packages: googleapis-common-protos, tensorflow-metadata, dill, tqdm, future, promise, tensorflow-datasets\n",
      "Successfully installed dill-0.3.1.1 future-0.18.2 googleapis-common-protos-1.51.0 promise-2.3 tensorflow-datasets-2.0.0 tensorflow-metadata-0.21.1 tqdm-4.43.0\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 4.2MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: six in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from bert-tensorflow) (1.11.0)\n",
      "Installing collected packages: bert-tensorflow\n",
      "Successfully installed bert-tensorflow-1.0.1\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#tf.enable_eager_execution()\n",
    "#tf.executing_eagerly()\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_hub as hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets, info = tfds.load(\"imdb_reviews\", as_supervised=True, with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = info.splits['train'].num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='imdb_reviews',\n",
       "    version=1.0.0,\n",
       "    description='Large Movie Review Dataset.\n",
       "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.',\n",
       "    homepage='http://ai.stanford.edu/~amaas/data/sentiment/',\n",
       "    features=FeaturesDict({\n",
       "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
       "        'text': Text(shape=(), dtype=tf.string),\n",
       "    }),\n",
       "    total_num_examples=100000,\n",
       "    splits={\n",
       "        'test': 25000,\n",
       "        'train': 25000,\n",
       "        'unsupervised': 50000,\n",
       "    },\n",
       "    supervised_keys=('text', 'label'),\n",
       "    citation=\"\"\"@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
       "      author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
       "      title     = {Learning Word Vectors for Sentiment Analysis},\n",
       "      booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
       "      month     = {June},\n",
       "      year      = {2011},\n",
       "      address   = {Portland, Oregon, USA},\n",
       "      publisher = {Association for Computational Linguistics},\n",
       "      pages     = {142--150},\n",
       "      url       = {http://www.aclweb.org/anthology/P11-1015}\n",
       "    }\"\"\",\n",
       "    redistribution_info=,\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preporcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bert import tokenization\n",
    "import bert\n",
    "\n",
    "# This is a path to an uncased (all lowercase) version of BERT\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    with tf.Graph().as_default():\n",
    "        bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "        tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "        with tf.Session() as sess:\n",
    "            vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                            tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "    return bert.tokenization.FullTokenizer(\n",
    "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'here',\n",
       " \"'\",\n",
       " 's',\n",
       " 'an',\n",
       " 'example',\n",
       " 'of',\n",
       " 'using',\n",
       " 'the',\n",
       " 'bert',\n",
       " 'token',\n",
       " '##izer']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"This here's an example of using the BERT tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sentence_to_features(sentence, tokenizer, max_seq_len):\n",
    "    tokens = ['[CLS]']\n",
    "    tokens.extend(tokenizer.tokenize(sentence))\n",
    "    if len(tokens) > max_seq_len-1:\n",
    "        tokens = tokens[:max_seq_len-1]\n",
    "    tokens.append('[SEP]')\n",
    "    \n",
    "    segment_ids = [0] * len(tokens)\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    #Zero Mask till seq_length\n",
    "    zero_mask = [0] * (max_seq_len-len(tokens))\n",
    "    input_ids.extend(zero_mask)\n",
    "    input_mask.extend(zero_mask)\n",
    "    segment_ids.extend(zero_mask)\n",
    "    \n",
    "    return input_ids, input_mask, segment_ids\n",
    "\n",
    "def convert_sentences_to_features(sentences, tokenizer, max_seq_len=20):\n",
    "    all_input_ids = []\n",
    "    all_input_mask = []\n",
    "    all_segment_ids = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        input_ids, input_mask, segment_ids = convert_sentence_to_features(sentence, tokenizer, max_seq_len)\n",
    "        all_input_ids.append(input_ids)\n",
    "        all_input_mask.append(input_mask)\n",
    "        all_segment_ids.append(segment_ids)\n",
    "    \n",
    "    return all_input_ids, all_input_mask, all_segment_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"\"\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\">, <tf.Tensor: id=20482, shape=(), dtype=int64, numpy=0>)\n",
    "(<tf.Tensor: id=20483, shape=(), dtype=string, numpy=b'I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However on this occasion I fell asleep because the film was rubbish. The plot development was constant. Constantly slow and boring. Things seemed to happen, but with no explanation of what was causing them or why. I admit, I may have missed part of the film, but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else. I cant recommend this film at all.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([101,\n",
       "  2023,\n",
       "  2001,\n",
       "  2019,\n",
       "  7078,\n",
       "  6659,\n",
       "  3185,\n",
       "  1012,\n",
       "  2123,\n",
       "  1005,\n",
       "  1056,\n",
       "  2022,\n",
       "  26673,\n",
       "  1999,\n",
       "  2011,\n",
       "  5696,\n",
       "  3328,\n",
       "  2368,\n",
       "  2030,\n",
       "  102],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_sentence_to_features(sentence, tokenizer, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[101,\n",
       "   2023,\n",
       "   2001,\n",
       "   2019,\n",
       "   7078,\n",
       "   6659,\n",
       "   3185,\n",
       "   1012,\n",
       "   2123,\n",
       "   1005,\n",
       "   1056,\n",
       "   2022,\n",
       "   26673,\n",
       "   1999,\n",
       "   2011,\n",
       "   5696,\n",
       "   3328,\n",
       "   2368,\n",
       "   2030,\n",
       "   102]],\n",
       " [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_sentences_to_features([sentence], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: id=20481, shape=(), dtype=string, numpy=b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\">, <tf.Tensor: id=20482, shape=(), dtype=int64, numpy=0>)\n",
      "(<tf.Tensor: id=20483, shape=(), dtype=string, numpy=b'I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However on this occasion I fell asleep because the film was rubbish. The plot development was constant. Constantly slow and boring. Things seemed to happen, but with no explanation of what was causing them or why. I admit, I may have missed part of the film, but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else. I cant recommend this film at all.'>, <tf.Tensor: id=20484, shape=(), dtype=int64, numpy=0>)\n",
      "(<tf.Tensor: id=20485, shape=(), dtype=string, numpy=b'Mann photographs the Alberta Rocky Mountains in a superb fashion, and Jimmy Stewart and Walter Brennan give enjoyable performances as they always seem to do. <br /><br />But come on Hollywood - a Mountie telling the people of Dawson City, Yukon to elect themselves a marshal (yes a marshal!) and to enforce the law themselves, then gunfighters battling it out on the streets for control of the town? <br /><br />Nothing even remotely resembling that happened on the Canadian side of the border during the Klondike gold rush. Mr. Mann and company appear to have mistaken Dawson City for Deadwood, the Canadian North for the American Wild West.<br /><br />Canadian viewers be prepared for a Reefer Madness type of enjoyable howl with this ludicrous plot, or, to shake your head in disgust.'>, <tf.Tensor: id=20486, shape=(), dtype=int64, numpy=0>)\n",
      "(<tf.Tensor: id=20487, shape=(), dtype=string, numpy=b'This is the kind of film for a snowy Sunday afternoon when the rest of the world can go ahead with its own business as you descend into a big arm-chair and mellow for a couple of hours. Wonderful performances from Cher and Nicolas Cage (as always) gently row the plot along. There are no rapids to cross, no dangerous waters, just a warm and witty paddle through New York life at its best. A family film in every sense and one that deserves the praise it received.'>, <tf.Tensor: id=20488, shape=(), dtype=int64, numpy=1>)\n"
     ]
    }
   ],
   "source": [
    "for d in datasets['train'].take(4):\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(x):\n",
    "    return convert_sentences_to_features([x.numpy().decode('utf-8')], tokenizer)\n",
    "\n",
    "dataset_encoded = datasets['train'].map(lambda X, y: (tf.py_function(func=encoding, inp=[X], Tout=(tf.int16, tf.int16, tf.int16)), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: id=20613, shape=(3, 1, 20), dtype=int16, numpy=\n",
      "array([[[  101,  2023,  2001,  2019,  7078,  6659,  3185,  1012,  2123,\n",
      "          1005,  1056,  2022, 26673,  1999,  2011,  5696,  3328,  2368,\n",
      "          2030,   102]],\n",
      "\n",
      "       [[    1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1]],\n",
      "\n",
      "       [[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]], dtype=int16)>, <tf.Tensor: id=20614, shape=(), dtype=int64, numpy=0>)\n",
      "(<tf.Tensor: id=20619, shape=(3, 1, 20), dtype=int16, numpy=\n",
      "array([[[ 101, 1045, 2031, 2042, 2124, 2000, 2991, 6680, 2076, 3152,\n",
      "         1010, 2021, 2023, 2003, 2788, 2349, 2000, 1037, 5257,  102]],\n",
      "\n",
      "       [[   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1]],\n",
      "\n",
      "       [[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0]]],\n",
      "      dtype=int16)>, <tf.Tensor: id=20620, shape=(), dtype=int64, numpy=0>)\n",
      "(<tf.Tensor: id=20625, shape=(3, 1, 20), dtype=int16, numpy=\n",
      "array([[[  101, 10856,  7008,  1996,  7649,  6857,  4020,  1999,  1037,\n",
      "         21688,  4827,  1010,  1998,  5261,  5954,  1998,  4787, 13962,\n",
      "          2507,   102]],\n",
      "\n",
      "       [[    1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1]],\n",
      "\n",
      "       [[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]], dtype=int16)>, <tf.Tensor: id=20626, shape=(), dtype=int64, numpy=0>)\n",
      "(<tf.Tensor: id=20631, shape=(3, 1, 20), dtype=int16, numpy=\n",
      "array([[[  101,  2023,  2003,  1996,  2785,  1997,  2143,  2005,  1037,\n",
      "         20981,  4465,  5027,  2043,  1996,  2717,  1997,  1996,  2088,\n",
      "          2064,   102]],\n",
      "\n",
      "       [[    1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1]],\n",
      "\n",
      "       [[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]], dtype=int16)>, <tf.Tensor: id=20632, shape=(), dtype=int64, numpy=1>)\n"
     ]
    }
   ],
   "source": [
    "for X_batch in dataset_encoded.take(4):\n",
    "    print(X_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = dataset_encoded.batch(32).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[  101  2023  2001 ...  2368  2030   102]]\n",
      "\n",
      "  [[    1     1     1 ...     1     1     1]]\n",
      "\n",
      "  [[    0     0     0 ...     0     0     0]]]\n",
      "\n",
      "\n",
      " [[[  101  1045  2031 ...  1037  5257   102]]\n",
      "\n",
      "  [[    1     1     1 ...     1     1     1]]\n",
      "\n",
      "  [[    0     0     0 ...     0     0     0]]]\n",
      "\n",
      "\n",
      " [[[  101 10856  7008 ... 13962  2507   102]]\n",
      "\n",
      "  [[    1     1     1 ...     1     1     1]]\n",
      "\n",
      "  [[    0     0     0 ...     0     0     0]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[  101  2023  3185 ...  2006  4966   102]]\n",
      "\n",
      "  [[    1     1     1 ...     1     1     1]]\n",
      "\n",
      "  [[    0     0     0 ...     0     0     0]]]\n",
      "\n",
      "\n",
      " [[[  101  3505 10184 ...  6424  1000   102]]\n",
      "\n",
      "  [[    1     1     1 ...     1     1     1]]\n",
      "\n",
      "  [[    0     0     0 ...     0     0     0]]]\n",
      "\n",
      "\n",
      " [[[  101  1006  9826 ... 25230  2075   102]]\n",
      "\n",
      "  [[    1     1     1 ...     1     1     1]]\n",
      "\n",
      "  [[    0     0     0 ...     0     0     0]]]], shape=(32, 3, 1, 20), dtype=int16)\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y in train_set.take(1):\n",
    "    print(X_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "\n",
    "bert_module = hub.Module(bert, trainable=False, \n",
    "   name='bexrt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tensor conversion requested dtype int32 for Tensor with dtype float32: 'Tensor(\"input_ids:0\", shape=(?, 20), dtype=float32)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-eaca01d3b390>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbert_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m       as_dict=True)\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Use \"pooled_output\" for classification tasks on an entire sentence.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_hub/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, _sentinel, signature, as_dict)\u001b[0m\n\u001b[1;32m    254\u001b[0m     dict_inputs = _convert_dict_inputs(\n\u001b[1;32m    255\u001b[0m         inputs, self._spec.get_input_info_dict(signature=signature,\n\u001b[0;32m--> 256\u001b[0;31m                                                tags=self._tags))\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     dict_outputs = self._impl.create_apply_graph(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_hub/module.py\u001b[0m in \u001b[0;36m_convert_dict_inputs\u001b[0;34m(inputs, tensor_info_map)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0mdict_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_dict_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_info_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   return tensor_info.convert_dict_to_compatible_tensor(dict_inputs,\n\u001b[0;32m--> 458\u001b[0;31m                                                        tensor_info_map)\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_hub/tensor_info.py\u001b[0m in \u001b[0;36mconvert_dict_to_compatible_tensor\u001b[0;34m(values, targets)\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     result[key] = _convert_to_compatible_tensor(\n\u001b[0;32m--> 150\u001b[0;31m         value, targets[key], error_prefix=\"Can't convert %r\" % key)\n\u001b[0m\u001b[1;32m    151\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_hub/tensor_info.py\u001b[0m in \u001b[0;36m_convert_to_compatible_tensor\u001b[0;34m(value, target, error_prefix)\u001b[0m\n\u001b[1;32m    117\u001b[0m   \"\"\"\n\u001b[1;32m    118\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_v1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor_or_indexed_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merror_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py\u001b[0m in \u001b[0;36mconvert_to_tensor_or_indexed_slices\u001b[0;34m(value, dtype, name)\u001b[0m\n\u001b[1;32m    269\u001b[0m   \"\"\"\n\u001b[1;32m    270\u001b[0m   return internal_convert_to_tensor_or_indexed_slices(\n\u001b[0;32m--> 271\u001b[0;31m       value=value, dtype=dtype, name=name, as_ref=False)\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor_or_indexed_slices\u001b[0;34m(value, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    303\u001b[0m       raise ValueError(\n\u001b[1;32m    304\u001b[0m           \u001b[0;34m\"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m           (dtypes.as_dtype(dtype).name, value.dtype.name, str(value)))\n\u001b[0m\u001b[1;32m    306\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor conversion requested dtype int32 for Tensor with dtype float32: 'Tensor(\"input_ids:0\", shape=(?, 20), dtype=float32)'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Build model\n",
    "max_seq_length = 20\n",
    "in_id = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_ids\")\n",
    "in_mask = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_masks\")\n",
    "in_segment = tf.keras.layers.Input(shape=(max_seq_length,), name=\"segment_ids\")\n",
    "\n",
    "\n",
    "\n",
    "bert_inputs = dict(\n",
    "      input_ids=in_id,\n",
    "      input_mask=in_mask,\n",
    "      segment_ids=in_segment)\n",
    "\n",
    "bert_outputs = bert_module(\n",
    "      inputs=bert_inputs,\n",
    "      signature=\"tokens\",\n",
    "      as_dict=True)\n",
    "\n",
    "# Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "# Use \"sequence_outputs\" for token-level output.\n",
    "output_layer = bert_outputs[\"pooled_output\"]\n",
    "\n",
    "hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "hidden = keras.layers.Dense(128, activation=\"relu\")(output_layer)\n",
    "output = keras.layers.Dense(1, activation=\"sigmoid\")(hidden)\n",
    "\n",
    "\n",
    "model = keras.Model(inputs=[in_id, in_mask, in_segment], outputs=[output])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "train_set,\n",
    "    epochs=1,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "max_seq_length = 20\n",
    "in_id = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_ids\")\n",
    "in_mask = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_masks\")\n",
    "in_segment = tf.keras.layers.Input(shape=(max_seq_length,), name=\"segment_ids\")\n",
    "\n",
    "bert_inputs = [in_id, in_mask, in_segment]\n",
    "\n",
    "# Instantiate the custom Bert Layer defined above\n",
    "bert_output = BertLayer(n_fine_tune_layers=10)(bert_inputs)\n",
    "\n",
    "# Build the rest of the classifier \n",
    "dense = tf.keras.layers.Dense(256, activation='relu')(bert_output)\n",
    "pred = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(\n",
    "train_set,\n",
    "    validation_data=([test_input_ids, test_input_masks, test_segment_ids], test_labels),\n",
    "    epochs=1,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_path = BERT_MODEL_HUB\n",
    "from keras import backend as K\n",
    "\n",
    "class BertLayer(tf.layers.Layer):\n",
    "    def __init__(self, n_fine_tune_layers=10, **kwargs):\n",
    "        self.n_fine_tune_layers = n_fine_tune_layers\n",
    "        self.trainable = True\n",
    "        self.output_size = 768\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.bert = hub.Module(\n",
    "            bert_path,\n",
    "            trainable=self.trainable,\n",
    "            name=\"{}_module\".format(self.name)\n",
    "        )\n",
    "        trainable_vars = self.bert.variables\n",
    "        \n",
    "        # Remove unused layers\n",
    "        trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n",
    "        \n",
    "        # Select how many layers to fine tune\n",
    "        trainable_vars = trainable_vars[-self.n_fine_tune_layers :]\n",
    "        \n",
    "        # Add to trainable weights\n",
    "        for var in trainable_vars:\n",
    "            self._trainable_weights.append(var)\n",
    "        \n",
    "        # Add non-trainable weights\n",
    "        for var in self.bert.variables:\n",
    "            if var not in self._trainable_weights:\n",
    "                self._non_trainable_weights.append(var)\n",
    "        \n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(\n",
    "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
    "        )\n",
    "        result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "            \"pooled_output\"\n",
    "        ]\n",
    "        return result\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f2bd1350798>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: <cyfunction Socket.send at 0x7f2bd9fe13e0> is not a module, class, method, function, traceback, frame, or code object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Using `hub.Module` while building a function: keras_graph. This can lead to errors if the function is not pruned.WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f2bd1350798>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: <cyfunction Socket.send at 0x7f2bd9fe13e0> is not a module, class, method, function, traceback, frame, or code object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f2bd1350798>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: <cyfunction Socket.send at 0x7f2bd9fe13e0> is not a module, class, method, function, traceback, frame, or code object\n",
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f2bd1350798>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: <cyfunction Socket.send at 0x7f2bd9fe13e0> is not a module, class, method, function, traceback, frame, or code object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f2bd1350798>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: <cyfunction Socket.send at 0x7f2bd9fe13e0> is not a module, class, method, function, traceback, frame, or code object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f2bd1350798>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: <cyfunction Socket.send at 0x7f2bd9fe13e0> is not a module, class, method, function, traceback, frame, or code object\n",
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f2bd1350798>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: <cyfunction Socket.send at 0x7f2bd9fe13e0> is not a module, class, method, function, traceback, frame, or code object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f2bd1350798>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: <cyfunction Socket.send at 0x7f2bd9fe13e0> is not a module, class, method, function, traceback, frame, or code object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f2bd1350798>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: <cyfunction Socket.send at 0x7f2bd9fe13e0> is not a module, class, method, function, traceback, frame, or code object\n",
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f2bd1350798>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: <cyfunction Socket.send at 0x7f2bd9fe13e0> is not a module, class, method, function, traceback, frame, or code object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f2bd1350798>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: <cyfunction Socket.send at 0x7f2bd9fe13e0> is not a module, class, method, function, traceback, frame, or code object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f2bd1350798>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: <cyfunction Socket.send at 0x7f2bd9fe13e0> is not a module, class, method, function, traceback, frame, or code object\n",
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f2bd1350798>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: <cyfunction Socket.send at 0x7f2bd9fe13e0> is not a module, class, method, function, traceback, frame, or code object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f2bd1350798>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: <cyfunction Socket.send at 0x7f2bd9fe13e0> is not a module, class, method, function, traceback, frame, or code object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f2bd1350798>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: <cyfunction Socket.send at 0x7f2bd9fe13e0> is not a module, class, method, function, traceback, frame, or code object\n",
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f2bd1350798>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: <cyfunction Socket.send at 0x7f2bd9fe13e0> is not a module, class, method, function, traceback, frame, or code object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f2bd1350798>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: <cyfunction Socket.send at 0x7f2bd9fe13e0> is not a module, class, method, function, traceback, frame, or code object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f2bd1350798>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: <cyfunction Socket.send at 0x7f2bd9fe13e0> is not a module, class, method, function, traceback, frame, or code object\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "The following are legacy tf.layers.Layers:\n  <__main__.BertLayer object at 0x7f2aabc1ad68>\nTo use keras as a framework (for instance using the Network, Model, or Sequential classes), please use the tf.keras.layers implementation instead. (Or, if writing custom layers, subclass from tf.keras.layers rather than tf.layers)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-a519f6833804>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbert_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m model.fit(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m     \u001b[0m_keras_api_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;31m# initializing _distribution_strategy here since it is possible to call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_subclassed_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_no_legacy_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m   \u001b[0;31m# Several Network methods have \"no_automatic_dependency_tracking\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36massert_no_legacy_layers\u001b[0;34m(layers)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;34m'classes), please use the tf.keras.layers implementation instead. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;34m'(Or, if writing custom layers, subclass from tf.keras.layers rather '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         'than tf.layers)'.format(layer_str))\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: The following are legacy tf.layers.Layers:\n  <__main__.BertLayer object at 0x7f2aabc1ad68>\nTo use keras as a framework (for instance using the Network, Model, or Sequential classes), please use the tf.keras.layers implementation instead. (Or, if writing custom layers, subclass from tf.keras.layers rather than tf.layers)"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "max_seq_length = 20\n",
    "in_id = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_ids\")\n",
    "in_mask = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_masks\")\n",
    "in_segment = tf.keras.layers.Input(shape=(max_seq_length,), name=\"segment_ids\")\n",
    "\n",
    "bert_inputs = [in_id, in_mask, in_segment]\n",
    "\n",
    "# Instantiate the custom Bert Layer defined above\n",
    "bert_output = BertLayer(n_fine_tune_layers=10)(bert_inputs)\n",
    "\n",
    "# Build the rest of the classifier \n",
    "dense = tf.keras.layers.Dense(256, activation='relu')(bert_output)\n",
    "pred = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(\n",
    "train_set,\n",
    "    validation_data=([test_input_ids, test_input_masks, test_segment_ids], test_labels),\n",
    "    epochs=1,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark\n",
    "http://nlpprogress.com/english/sentiment_analysis.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 128\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Embedding(vocab_size + num_oov_buckets, embed_size, input_shape=[None], mask_zero=True),\n",
    "    keras.layers.GRU(128, return_sequences=True),\n",
    "    keras.layers.GRU(128,),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "batch_size=32\n",
    "num_epochs=15\n",
    "steps_per_epoch_train = train_size // num_epochs // batch_size\n",
    "steps_per_epoch_test = train_size // num_epochs // batch_size\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(train_set, epochs=num_epochs, steps_per_epoch=steps_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained embedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "num_epochs=15\n",
    "\n",
    "datasets, info = tfds.load(\"imdb_reviews\", as_supervised=True, with_info=True)\n",
    "                           \n",
    "train_size = info.splits[\"train\"].num_examples\n",
    "train_set = datasets[\"train\"].repeat().batch(batch_size).prefetch(1)\n",
    "\n",
    "test_size = info.splits[\"test\"].num_examples\n",
    "test_set = datasets[\"test\"].repeat().batch(batch_size).prefetch(1)\n",
    "\n",
    "\n",
    "                           \n",
    "steps_per_epoch_train = train_size // num_epochs // batch_size\n",
    "steps_per_epoch_test = train_size // num_epochs // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: id=212, shape=(32,), dtype=string, numpy=\n",
      "array([b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\",\n",
      "       b'I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However on this occasion I fell asleep because the film was rubbish. The plot development was constant. Constantly slow and boring. Things seemed to happen, but with no explanation of what was causing them or why. I admit, I may have missed part of the film, but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else. I cant recommend this film at all.',\n",
      "       b'Mann photographs the Alberta Rocky Mountains in a superb fashion, and Jimmy Stewart and Walter Brennan give enjoyable performances as they always seem to do. <br /><br />But come on Hollywood - a Mountie telling the people of Dawson City, Yukon to elect themselves a marshal (yes a marshal!) and to enforce the law themselves, then gunfighters battling it out on the streets for control of the town? <br /><br />Nothing even remotely resembling that happened on the Canadian side of the border during the Klondike gold rush. Mr. Mann and company appear to have mistaken Dawson City for Deadwood, the Canadian North for the American Wild West.<br /><br />Canadian viewers be prepared for a Reefer Madness type of enjoyable howl with this ludicrous plot, or, to shake your head in disgust.',\n",
      "       b'This is the kind of film for a snowy Sunday afternoon when the rest of the world can go ahead with its own business as you descend into a big arm-chair and mellow for a couple of hours. Wonderful performances from Cher and Nicolas Cage (as always) gently row the plot along. There are no rapids to cross, no dangerous waters, just a warm and witty paddle through New York life at its best. A family film in every sense and one that deserves the praise it received.',\n",
      "       b'As others have mentioned, all the women that go nude in this film are mostly absolutely gorgeous. The plot very ably shows the hypocrisy of the female libido. When men are around they want to be pursued, but when no \"men\" are around, they become the pursuers of a 14 year old boy. And the boy becomes a man really fast (we should all be so lucky at this age!). He then gets up the courage to pursue his true love.',\n",
      "       b\"This is a film which should be seen by anybody interested in, effected by, or suffering from an eating disorder. It is an amazingly accurate and sensitive portrayal of bulimia in a teenage girl, its causes and its symptoms. The girl is played by one of the most brilliant young actresses working in cinema today, Alison Lohman, who was later so spectacular in 'Where the Truth Lies'. I would recommend that this film be shown in all schools, as you will never see a better on this subject. Alison Lohman is absolutely outstanding, and one marvels at her ability to convey the anguish of a girl suffering from this compulsive disorder. If barometers tell us the air pressure, Alison Lohman tells us the emotional pressure with the same degree of accuracy. Her emotional range is so precise, each scene could be measured microscopically for its gradations of trauma, on a scale of rising hysteria and desperation which reaches unbearable intensity. Mare Winningham is the perfect choice to play her mother, and does so with immense sympathy and a range of emotions just as finely tuned as Lohman's. Together, they make a pair of sensitive emotional oscillators vibrating in resonance with one another. This film is really an astonishing achievement, and director Katt Shea should be proud of it. The only reason for not seeing it is if you are not interested in people. But even if you like nature films best, this is after all animal behaviour at the sharp edge. Bulimia is an extreme version of how a tormented soul can destroy her own body in a frenzy of despair. And if we don't sympathise with people suffering from the depths of despair, then we are dead inside.\",\n",
      "       b'Okay, you have:<br /><br />Penelope Keith as Miss Herringbone-Tweed, B.B.E. (Backbone of England.) She\\'s killed off in the first scene - that\\'s right, folks; this show has no backbone!<br /><br />Peter O\\'Toole as Ol\\' Colonel Cricket from The First War and now the emblazered Lord of the Manor.<br /><br />Joanna Lumley as the ensweatered Lady of the Manor, 20 years younger than the colonel and 20 years past her own prime but still glamourous (Brit spelling, not mine) enough to have a toy-boy on the side. It\\'s alright, they have Col. Cricket\\'s full knowledge and consent (they guy even comes \\'round for Christmas!) Still, she\\'s considerate of the colonel enough to have said toy-boy her own age (what a gal!)<br /><br />David McCallum as said toy-boy, equally as pointlessly glamourous as his squeeze. Pilcher couldn\\'t come up with any cover for him within the story, so she gave him a hush-hush job at the Circus.<br /><br />and finally:<br /><br />Susan Hampshire as Miss Polonia Teacups, Venerable Headmistress of the Venerable Girls\\' Boarding-School, serving tea in her office with a dash of deep, poignant advice for life in the outside world just before graduation. Her best bit of advice: \"I\\'ve only been to Nancherrow (the local Stately Home of England) once. I thought it was very beautiful but, somehow, not part of the real world.\" Well, we can\\'t say they didn\\'t warn us.<br /><br />Ah, Susan - time was, your character would have been running the whole show. They don\\'t write \\'em like that any more. Our loss, not yours.<br /><br />So - with a cast and setting like this, you have the re-makings of \"Brideshead Revisited,\" right?<br /><br />Wrong! They took these 1-dimensional supporting roles because they paid so well. After all, acting is one of the oldest temp-jobs there is (YOU name another!)<br /><br />First warning sign: lots and lots of backlighting. They get around it by shooting outdoors - \"hey, it\\'s just the sunlight!\"<br /><br />Second warning sign: Leading Lady cries a lot. When not crying, her eyes are moist. That\\'s the law of romance novels: Leading Lady is \"dewy-eyed.\"<br /><br />Henceforth, Leading Lady shall be known as L.L.<br /><br />Third warning sign: L.L. actually has stars in her eyes when she\\'s in love. Still, I\\'ll give Emily Mortimer an award just for having to act with that spotlight in her eyes (I wonder . did they use contacts?)<br /><br />And lastly, fourth warning sign: no on-screen female character is \"Mrs.\" She\\'s either \"Miss\" or \"Lady.\"<br /><br />When all was said and done, I still couldn\\'t tell you who was pursuing whom and why. I couldn\\'t even tell you what was said and done.<br /><br />To sum up: they all live through World War II without anything happening to them at all.<br /><br />OK, at the end, L.L. finds she\\'s lost her parents to the Japanese prison camps and baby sis comes home catatonic. Meanwhile (there\\'s always a \"meanwhile,\") some young guy L.L. had a crush on (when, I don\\'t know) comes home from some wartime tough spot and is found living on the street by Lady of the Manor (must be some street if SHE\\'s going to find him there.) Both war casualties are whisked away to recover at Nancherrow (SOMEBODY has to be \"whisked away\" SOMEWHERE in these romance stories!)<br /><br />Great drama.',\n",
      "       b'The film is based on a genuine 1950s novel.<br /><br />Journalist Colin McInnes wrote a set of three \"London novels\": \"Absolute Beginners\", \"City of Spades\" and \"Mr Love and Justice\". I have read all three. The first two are excellent. The last, perhaps an experiment that did not come off. But McInnes\\'s work is highly acclaimed; and rightly so. This musical is the novelist\\'s ultimate nightmare - to see the fruits of one\\'s mind being turned into a glitzy, badly-acted, soporific one-dimensional apology of a film that says it captures the spirit of 1950s London, and does nothing of the sort.<br /><br />Thank goodness Colin McInnes wasn\\'t alive to witness it.',\n",
      "       b'I really love the sexy action and sci-fi films of the sixties and its because of the actress\\'s that appeared in them. They found the sexiest women to be in these films and it didn\\'t matter if they could act (Remember \"Candy\"?). The reason I was disappointed by this film was because it wasn\\'t nostalgic enough. The story here has a European sci-fi film called \"Dragonfly\" being made and the director is fired. So the producers decide to let a young aspiring filmmaker (Jeremy Davies) to complete the picture. They\\'re is one real beautiful woman in the film who plays Dragonfly but she\\'s barely in it. Film is written and directed by Roman Coppola who uses some of his fathers exploits from his early days and puts it into the script. I wish the film could have been an homage to those early films. They could have lots of cameos by actors who appeared in them. There is one actor in this film who was popular from the sixties and its John Phillip Law (Barbarella). Gerard Depardieu, Giancarlo Giannini and Dean Stockwell appear as well. I guess I\\'m going to have to continue waiting for a director to make a good homage to the films of the sixties. If any are reading this, \"Make it as sexy as you can\"! I\\'ll be waiting!',\n",
      "       b'Sure, this one isn\\'t really a blockbuster, nor does it target such a position. \"Dieter\" is the first name of a quite popular German musician, who is either loved or hated for his kind of acting and thats exactly what this movie is about. It is based on the autobiography \"Dieter Bohlen\" wrote a few years ago but isn\\'t meant to be accurate on that. The movie is filled with some sexual offensive content (at least for American standard) which is either amusing (not for the other \"actors\" of course) or dumb - it depends on your individual kind of humor or on you being a \"Bohlen\"-Fan or not. Technically speaking there isn\\'t much to criticize. Speaking of me I find this movie to be an OK-movie.',\n",
      "       b'During a sleepless night, I was switching through the channels & found this embarrassment of a movie. What were they thinking?<br /><br />If this is life after \"Remote Control\" for Kari (Wuhrer) Salin, no wonder she\\'s gone nowhere.<br /><br />And why did David Keith take this role? It\\'s pathetic!<br /><br />Anyway, I turned on the movie near the end, so I didn\\'t get much of the plot. But this must\\'ve been the best part. This nerdy college kid brings home this dominatrix-ish girl...this scene is straight out of the comic books -- or the cheap porn movies. She calls the mother anal retentive and kisses the father \"Oh, I didn\\'t expect tongue!\" Great lines!<br /><br />After this, I had to see how it ended..<br /><br />Well, of course, this bitch from hell has a helluva past, so the SWAT team is upstairs. And yes...they surround her! And YES YES! The kid blows her brains out!!!! AHAHHAHAHAHA!!<br /><br />This is must-see TV. <br /><br />',\n",
      "       b'Cute film about three lively sisters from Switzerland (often seen running about in matching outfits) who want to get their parents back together (seems mom is still carrying the torch for dad) - so they sail off to New York to stop the dad from marrying a blonde gold-digger he calls \"Precious\". Dad hasn\\'t seen his daughters in ten years, they (oddly enough) don\\'t seem to mind and think he\\'s wonderful, and meanwhile Precious seems to lead a life mainly run by her overbearing mother (Alice Brady), a woman who just wants to see to it her daughter marries a rich man. The sisters get the idea of pushing Precious into the path of a drunken Hungarian count, tricking the two gold-digging women into thinking he is one of the richest men in Europe. But a case of mistaken identity makes the girls think the count is good-looking Ray Milland, who goes along with the scheme \\'cause he has a crush on sister Kay.<br /><br />This film is enjoyable, light fare. Barbara Read as Kay comes across as sweet and pretty, Ray Milland looks oh so young and handsome here (though, unfortunately, is given little to do), Alice Brady is quite good as the scheming mother - but it is Deanna Durbin, a real charmer and cute as a button playing youngest sister Penny, who pretty much steals the show. With absolutely beautiful vocals, she sings several songs throughout the film, though I actually would have liked to have seen them feature her even more in this. The plot in this film is a bit silly, but nevertheless, I found the film to be entertaining and fun.',\n",
      "       b\"This 1984 version of the Dickens' classic `A Christmas Carol,' directed by Clive Donner, stars George C. Scott as Ebenezer Scrooge. By this time around, the challenge for the filmmaker was to take such familiar material and make it seem fresh and new again; and, happily to say, with this film Donner not only met the challenge but surpassed any expectations anyone might have had for it. He tells the story with precision and an eye to detail, and extracts performances from his actors that are nothing less than superlative, especially Scott. One could argue that the definitive portrayal of Scrooge-- one of the best known characters in literary fiction, ever-- was created by Alastair Sim in the 1951 film; but I think with his performance here, Scott has now achieved that distinction. There is such a purity and honesty in his Scrooge that it becomes difficult to even consider anyone else in the role once you've seen Scott do it; simply put, he IS Scrooge. And what a tribute it is to such a gifted actor; to be able to take such a well known figure and make it so uniquely his own is quite miraculous. It is truly a joy to see an actor ply his trade so well, to be able to make a character so real, from every word he utters down to the finest expression of his face, and to make it all ring so true. It's a study in perfection.<br /><br />The other members of the cast are splendid as well, but then again they have to be in order to maintain the integrity of Scott's performance; and they do. Frank Finlay is the Ghost of Jacob Marley; a notable turn, though not as memorable, perhaps, as the one by Alec Guinness (as Marley) in the film, `Scrooge.' Angela Pleasence is a welcome visage as the Spirit of Christmas Past; Edward Woodward, grand and boisterous, and altogether convincing as the Spirit of Christmas Present; and Michael Carter, grim and menacing as the Spirit of Christmas Yet To Come.<br /><br />David Warner hits just the right mark with his Bob Cratchit, bringing a sincerity to the role that measures up well to the standard of quality set by Scott's Scrooge, and Susannah York fares just as well as Mrs. Cratchit. The real gem to be found here, though, is the performance of young Anthony Walters as Tiny Tim; it's heartfelt without ever becoming maudlin, and simply one of the best interpretations-- and the most real-- ever presented on film.<br /><br />The excellent supporting cast includes Roger Rees (Fred Holywell, and also the narrator of the film), Caroline Langrishe (Janet Holywell), Lucy Gutteridge (Belle), Michael Gough (Mr. Poole) and Joanne Whalley (Fan). A flawless presentation, this version of `A Christmas Carol' sets the standard against which all others must be gauged; no matter how many versions you may have seen, watching this one is like seeing it for the first time ever. And forever after, whenever you think of Scrooge, the image your mind will conjure up will be that of George C. Scott. A thoroughly entertaining and satisfying experience, this film demands a place in the annual schedule of the holiday festivities of every home. I rate this one 10/10.\",\n",
      "       b'Put the blame on executive producer Wes Craven and financiers the Weinsteins for this big-budget debacle: a thrash-metal updating of \"Dracula\", with a condescending verbal jab at Bram Stoker (who probably wouldn\\'t want his name on this thing anyway) and nothing much for the rest of us except slasher-styled jolts and gore. Christopher Plummer looks winded as Van Helsing in the modern-day--not just a descendant of Van Helsing but the real thing; he keeps himself going with leeches obtained from Count Dracula\\'s corpse, which is exhumed from its coffin after being stolen from Van Helsing\\'s vault and flown to New Orleans. This is just what New Orleans needs in the 21st Century! The film, well-produced but without a single original idea (except for multi-racial victims), is both repulsive and lazy, and after about an hour starts repeating itself. * from ****',\n",
      "       b'Hilarious, evocative, confusing, brilliant film. Reminds me of Bunuel\\'s L\\'Age D\\'Or or Jodorowsky\\'s Holy Mountain-- lots of strange characters mucking about and looking for..... what is it? I laughed almost the whole way through, all the while keeping a peripheral eye on the bewildered and occasionally horrified reactions of the audience that surrounded me in the theatre. Entertaining through and through, from the beginning to the guts and poisoned entrails all the way to the end, if it was an end. I only wish i could remember every detail. It haunts me sometimes.<br /><br />Honestly, though, i have only the most positive recollections of this film. As it doesn\\'t seem to be available to take home and watch, i suppose i\\'ll have to wait a few more years until Crispin Glover comes my way again with his Big Slide Show (and subsequent \"What is it?\" screening)... I saw this film in Atlanta almost directly after being involved in a rather devastating car crash, so i was slightly dazed at the time, which was perhaps a very good state of mind to watch the prophetic talking arthropods and the retards in the superhero costumes and godlike Glover in his appropriate burly-Q setting, scantily clad girlies rising out of the floor like a magnificent DADAist wet dream.<br /><br />Is it a statement on Life As We Know It? Of course everyone EXPECTS art to be just that. I rather think that the truth is more evident in the absences and in the negative space. What you don\\'t tell us is what we must deduce, but is far more valid than the lies that other people feed us day in and day out. Rather one \"WHAT IS IT?\" than 5000 movies like \"Titanic\" or \"Sleepless in Seattle\" (shudder, gag, groan).<br /><br />Thank you, Mr. Glover (additionally a fun man to watch on screen or at his Big Slide Show-- smart, funny, quirky, and outrageously hot). Make more films, write more books, keep the nightmare alive.',\n",
      "       b'It was disgusting and painful. What a waste of a cast! I swear, the audience (1/2 full) laughed TWICE in 90 minutes. This is not a lie. Do not even rent it.<br /><br />Zeta Jones was just too mean to be believable.<br /><br />Cusack was OK. Just OK. I felt sorry for him (the actor) in case people remember this mess.<br /><br />Roberts was the same as she always is. Charming and sweet, but with no purpose. The \"romance\" with John was completely unbelievable.',\n",
      "       b'This is a straight-to-video movie, so it should go without saying that it\\'s not going to rival the first Lion King, but that said, this was downright good.<br /><br />My kids loved this, but that\\'s a given, they love anything that\\'s a cartoon. The big shock was that *I* liked it too, it was laugh out loud funny at some parts (even the fart jokes*), had lots of rather creative tie-ins with the first movie, and even some jokes that you had to be older to understand (but without being risqu\\xc3\\xa9 like in Shrek [\"do you think he\\'s compensating for something?\"]).<br /><br />A special note on the fart jokes, I was surprised to find that none of the jokes were just toilet noises (in fact there were almost no noises/imagery at all, the references were actually rather subtle), they actually had a setup/punchline/etc, and were almost in good taste. I\\'d like my kids to think that there\\'s more to humor than going to the bathroom, and this movie is fine in those regards.<br /><br />Hmm what else? The music was so-so, not nearly as creative as in the first or second movie, but plenty of fun for the kids. No painfully corny moments, which was a blessing for me. A little action but nothing too scary (the Secret of NIMH gave my kids nightmares, not sure a G rating was appropriate for that one...)<br /><br />All in all I\\'d say this is a great movie for kids of any age, one that\\'s 100% safe to let them watch (I try not to be overly sensitive but I\\'ve had to jump up and turn off the TV during a few movies that were less kid-appropriate than expected) - but you\\'re safe to leave the room during this one. I\\'d say stick around anyway though, you might find that you enjoy it too :)',\n",
      "       b'Finally, Timon and Pumbaa in their own film...<br /><br />\\'The Lion King 1 1/2: Hakuna Matata\\' is an irreverent new take on a classic tale. Which classic tale, you ask? Why, \\'The Lion King\\' of course!<br /><br />Yep, if there\\'s one thing that Disney is never short of, it\\'s narcissism.<br /><br />But that doesn\\'t mean that this isn\\'t a good film. It\\'s basically the events of \\'The Lion King\\' as told from Timon and Pumbaa\\'s perspective. And it\\'s because of this that you\\'ll have to know the story of \\'The Lion King\\' by heart to see where they\\'re coming from.<br /><br />Anyway, at one level I was watching this and thinking \"Oh my god this is so lame...\" and on another level I was having a ball. Much of the humour is predictable - I mean, when Pumbaa makes up two beds, a big one for himself and a small one for Timon, within the first nanosecond we all know that Timon is going to take the big one. But that doesn\\'t stop it from being hilarious, which, IMO, is \\'Hakuna Matata\\' in a nutshell. It\\'s not what happens, it\\'s how.<br /><br />And a note of warning: there are also some fart jokes. Seriously, did you expect anything else in a film where Pumbaa takes centre stage? But as fart jokes go, these are especially good, and should satisfy even the most particular connoisseur.<br /><br />The returning voice talent is great. I\\'m kinda surprised that some of the actors were willing to return, what with most of them only having two or three lines (if they\\'re lucky). Whoopi Goldberg is particularly welcome.<br /><br />The music is also great. From \\'Digga Tunnah\\' at the start to \\'That\\'s all I need\\', an adaption of \\'Warthog Rhapsody\\' (a song that was cut from \\'The Lion King\\' and is frankly much improved in this incarnation), the music leaves me with nothing to complain about whatsoever.<br /><br />In the end, Timon and Pumbaa are awesome characters, and while it may be argued that \\'Hakuna Matata\\' is simply an excuse to see them in various fun and assorted compromising situations then so be it. It\\'s rare to find characters that you just want to spend time with.<br /><br />Am I starting to sound creepy?<br /><br />Either way, \\'The Lion King 1 1/2\\' is great if you\\'ve seen \\'The Lion King\\' far too many times. Especially if you are right now thinking \"Don\\'t be silly, there\\'s no such thing as seeing \\'The Lion King\\' too many times!\"',\n",
      "       b'Indian Directors have it tough, They have to compete with movies like \"Laggan\" where 11 henpecked,Castrated males defend their village and half of them are certifiable idiots. \"Devdas\", a hapless, fedar- festooned foreign return drinking to oblivion, with characters running in endless corridors oblivious to any one\\'s feelings or sentiments-alas they live in an ornate squalor of red tapestry and pageantry. But to make a good movie, you have to tight-rope walk to appease the frontbenchers who are the quentessential gapers who are mesmerized with Split skirts and Dishum-Dishum fights preferably involving a nitwit \"Bollywood\" leading actor who is marginally handsome. So you can connect with a director who wants to tell a tale of Leonine village head who in own words \"defending his Village\" this is considered a violent movie or too masculine for a male audience. There are very few actors who can convey the anger and pathos like Nana Patekar (Narasimhan). Nana Patekar lets you in his courtyard and watch him beret and mock the Politician when his loyal admirers burst in laughter with every word of satire thrown at him, meanwhile his daughter is bathing his Grandson.This is as authentic a scene you can get in rural India. Nana Patekar is the essential actor who belongs to the old school of acting which is a disappearing breed in Hindi Films. The violence depicted is an intricate part of storytelling with Song&Dances thrown in for the gawkers without whom movies won\\'t sell, a sad but true state of affairs. Faster this changes better for \"Bollywood\". All said and done this is one good Movie.',\n",
      "       b\"Nathan Detroit runs illegal craps games for high rollers in NYC, but the heat is on and he can't find a secure location. He bets chronic gambler Sky Masterson that Sky can't make a prim missionary, Sarah Brown, go out to dinner with him. Sky takes up the challenge, but both men have some surprises in store \\xc2\\x85<br /><br />This is one of those expensive fifties MGM musicals in splashy colour, with big sets, loud music, larger-than-life roles and performances to match; Broadway photographed for the big screen if you like that sort of thing, which I don't. My main problem with these type of movies is simply the music. I like all kinds of music, from Albinoni to ZZ Top, but Broadway show tunes in swing time with never-ending pah-pah-tah-dah trumpet flourishes at the end of every fourth bar aren't my cup of tea. This was written by the tag team of Frank Loesser, Mankiewicz, Jo Swerling and Abe Burrows (based on a couple of Damon Runyon stories), and while the plot is quite affable the songs are weak. Blaine's two numbers for example are identical, unnecessary, don't advance the plot and grate on the ears (and are also flagrantly misogynistic if that sort of thing bothers you). There are only two memorable tunes, Luck Be A Lady (sung by Brando, not Sinatra as you might expect) and Sit Down, You're Rockin' The Boat (nicely performed by Kaye) but you have to sit through two hours to get to them. The movie's trump card is a young Brando giving a thoughtful, laid-back performance; he also sings quite well and even dances a little, and is evenly matched with the always interesting Simmons. The sequence where the two of them escape to Havana for the night is a welcome respite from all the noise, bustle and vowel-murdering of Noo Yawk. Fans of musicals may dig this, but in my view a musical has to do something more than just film the stage show.\",\n",
      "       b\"I can still remember first seeing this on TV. I couldn't believe TVNZ let it on! I had to own it! A lot of the humor will be lost on non-NZ'ers, but give it a go! <br /><br />Since finishing the Back of the Y series Matt and Chris have gone on to bigger and better(?) things. NZ's greatest dare-devil stuntman, Randy Campbell has often appeared on the British TV series Balls of Steel. Yes, he still f^@ks up all his stunts because he is too drunk.<br /><br />Also the 'house band' Deja Voodoo have since released 2 albums, Brown Sabbath and Back in Brown. The band consists of members of the Back of the Y team and singles such as 'I Would Give You One of My Beers (But I've Only Got 6)' and 'You Weren't Even Born in The 80's' continue their humor.<br /><br />The South-By-Southwest film festival also featured their feature length film 'The Devil Made Me Do It' which will be released early 2008 in NZ.<br /><br />All up, if you don't find these guys funny then you can just F%^K OFF!!\",\n",
      "       b'In a time of magic, barbarians and demons abound a diabolical tyrant named Nekhron and his mother Queen Juliane who lives in the realm of ice and wants to conquer the region of fire ruled by the King Jerol but when his beautiful daughter Princess Teegra has been kidnapped by Nekhron\\'s goons, a warrior named Larn must protect her and must defeat Nekhron from taking over the world and the kingdom with the help of an avenger named Darkwolf.<br /><br />A nicely done and excellent underrated animated fantasy epic that combines live actors with animation traced over them ( rotoscoping), it\\'s Ralph Bakshi\\'s second best movie only with \"American Pop\" being number one and \"Heavy Traffic\" being third and \"Wizards\" being fourth. It\\'s certainly better than his \"Cool World\" or \"Lord of the Rings\", the artwork is designed by famed artist Frank Farzetta and the animation has good coloring and there\\'s also a hottie for the guys.<br /><br />I highly recommend this movie to fantasy and animation lovers everywhere especially the new 2-Disc Limited Edition DVD from Blue Underground.<br /><br />Also recommended: \"The Black Cauldron\", \"The Dark Crystal\", \"Conan The Barbarian\", \"The Wizard of Oz\", \" Rock & Rule\", \"Wizards\", \"Heavy Metal\", \"Starchaser: Legend of Orin\", \"Fantastic Planet\", \" Princess Mononoke\", \" Nausicca: Valley of the Wind\", \" Conan The Destroyer\", \" Willow\", \" The Princess Bride\", \"Lord of the Rings ( 1978)\", \" The Sword in The Stone\", \" Excalibur\", \" Army of Darkness\", \" Krull\", \"Dragonheart\", \" King Arthur\", \" The Hobbit\", \" Return of the King ( 1980)\", \"Conquest\", \" American Pop\", \" Jason and The Argonauts\", \" Clash of the Titans\", \" The Last Unicorn\", \" The Secret of NIMH\", \"The Flight of Dragons\", \" Hercules (Disney)\", \" Legend\", \" The Chronicles of Narnia\", \" Harry Potter and The Goblet of Fire\".',\n",
      "       b'A pretty memorable movie of the animals-killing-people variety, specifically similar to \"Willard\" in that it stars an aging character actor (in this case, a step down a bit to the level of Les Tremayne, who puts in the only distinguished performance I\\'ve seen him give) in a role as a man whose life is unbalanced and who subsequently decides to use his animal friends to exact revenge on those who have wronged him. Yes, this is one of those movies where pretty much everybody is despicable, so that you will cheer when they die, and really the selection of actors, locations, etc. couldn\\'t be better at giving the film an atmosphere of shabby decadence.<br /><br />Tremayne\\'s character is \"Snakey Bender\", and he is certainly the most interesting thing about the movie: an aged snake collector who is obsessed with John Philip Souza\\'s music. When the local preacher clamps down on his practice of collecting small animals from the local schoolchildren as bait for his snakes, and his friend gets married to a stripper (thus upsetting his ritual Wednesday night band concert) he goes on the rampage, in the process creating a memorable pile-up of clunkers beneath the cliff where he dumps the wrecks after disposing of their unfortunate owners. One amusing game you can play while watching \"Snakes\" is to place bets on which cars will land the farthest down the cliff.<br /><br />All in all, very cheap and exploitative, but will really be a lot of fun for fans of these kinds of movies.',\n",
      "       b\"Except for an awkward scene, this refreshing fairy tale fantasy has a fun and delightful undercurrent of adult cynical wit that charms its way into the audience as well as a soundtrack that powerfully moves this fairy epic along. Except for one of the Robert DeNiro scenes that doesn't come across smooth and appears out of sync with the tone of the rest of the movie, this luscious romantic fairy tail has a great storytelling feel and the strong magic and the fine balance between serious adventure scenes and the lighter spiritual humor is well done. In the updated tradition of THE PRINCESS BRIDE this contemporary presentation of magic and love is captivating. Eight out of Ten Stars.\",\n",
      "       b'In this film we have the fabulous opportunity to see what happened to Timon and Pumbaa in the film when they are not shown - which is a lot! This film even goes back to before Simba and (presumbably) just after the birth of Kiara. <br /><br />Quite true to the first film, \"Lion King 1/2 (or Lion King 3 in other places)\" is a funny, entertaining, exciting and surprising film (or sequel if that\\'s what you want to call it). A bundle of surprises and hilarity await for you!<br /><br />While Timon and Pumbaa are watching a film at the cinema (with a remote control), Timon and Pumbaa have an argument of what point of \"The Lion King\" they are going to start watching, as Timon wants to go to the part when he and Pumbaa come in and Pumbaa wants to go back to the beginning. They have a very fair compromise of watching the film of their own story, which is what awaits... It starts with Timon\\'s first home...<br /><br />For anyone with a good sense of humour who liked the first films of just about any age, enjoy \"Lion King 1/2\"! :-)',\n",
      "       b\"Well, i rented this movie and found out it realllllllly sucks. It is about that family with the stepmother and the same stupid fights in the family,then the cool son comes with his stupid camera and he likes to take a photo to damaged building and weird things and weird movie ,and then he asks his father to take him to a side trip and simply agrees, etc etc etc..... They go to that town which no one know it exists (blah blah blah) And the most annoying thing is that the movie ends and yet you don't understand what is THAT MOVIE!!!!I have seen many mystery movies but that was the worst, Honestly it doesn't have a description at all and i wish i didn't see it.\",\n",
      "       b'I actually had quite high hopes going into this movie, so I took what was given with a grain of salt and hoped for the best. About 1/3 of the way through the film I simply had to give up, quite simply the movie is a mish-mash of stuff happening for no apparent reason and it\\'s all disconnected. I love movies that make you think, but this movie was just a bunch of ideas thrown together and never really connected.<br /><br />Don\\'t think it\\'s David Lynch-esquire as some would have you believe, it is nowhere near that realm other than some trippy visuals. Saying it\\'s artsy to disguise the fact there\\'s no apparent plot or story is just a manner or justifying why you wasted the 1.5 hours in the film. The acting was good, but that cannot save lack of story. I do agree with the one comment posted previously... \"it\\'s like being in some other person\\'s head... while they\\'re on drugs,\" in other words nothing makes sense.',\n",
      "       b\"I liked the initial premise to this film which is what led me to hunt it out but the problem I quickly found is that one pretty much knows what's going to happen within the first 20-30 minutes ( the doubles will come from behind the mirror and take over everybody).<br /><br />There is no real twist (which is fine) , but the final reveal doesn't make a great deal of sense either (how can she be racked with uncertainty and fear for the whole film, if she's an evil id from beyond the mirror?).<br /><br />Admittedly the scenes 'beyond the mirror' were chilling when they first appeared and the blonde's murder is also effectively creepy, but ultimately alas this seems to be a film in search of a story or a more engaging script, piling atmosphere upon atmosphere and over the top scary sound design for 80-90 minutes does not really cut it, in fact it gets quite dull.\",\n",
      "       b\"My main problem with the film is that it goes on too long. Other then that, it's pretty good. Paul Muni plays a poor Chinese farmer who is about to get married through an arranged marriage. Luise Rainer is a servant girl who gets married to Muni. They live with Muni's father on a farm and they are doing pretty bad. When he finally gets some money to buy some more land, a drought hits and nothing is growing. Everybody stars to head north by Muni stays behind at first. When they leave and arrive at town they find that their are no jobs and they are worse off than before. They even think about selling their youngest daughter as a slave for some money but decide against it. When a bunch of people start looting the town, the military show up and start executing people . Paul Muni does a good job and Luise Rainer won a second oscar for this movie.\",\n",
      "       b\"This movie never made it to theaters in our area, so when it became available on DVD I was one of the first to rent it. For once, I should listened to the critics and passed on this one.<br /><br />Despite the excellent line up of actors the movie was very disappointing. I can see now why it went straight to video. <br /><br />I had thought that with Bloom, Ledger, and Rush it could have some value. All have done wonderful work in the past. <br /><br />The movie was slow moving and never pulled me in. I failed to develop much empathy for the characters and had to fight the urge to fast-forward just to get to the end. <br /><br />I do not recommend this film even if you are thinking of renting it for only for 'eye candy' purposes. It won't satisfy even that.\",\n",
      "       b'Mike Brady (Michael Garfield who had a minuscule part in the classic \"The Warriors\") is the first person in the community to realize that there\\'s murderous slugs in his small town. Not just any slugs, mind you, but carnivorous killer bigger then normal, mutated by toxic waste slugs (who still only go as fast as a normal slug, which isn\\'t that frightening, but I digress). No one will believe him at first, but they will. Oh yes, they will.<br /><br />OK, killer slugs are right above psychotic sloths and right below Johnathon Winters as Mork\\'s baby in the creepiness factor. So the absurdness of it all is quite apparent from the get go. The flick is fun somewhat through and is of the \\'so bad that it\\'s good\\' variety. I appreciate that they spelled out that this was Slugs: the Movie as opposed to Slugs: the Children\\'s Game or Slugs: the Other White Meat. Probably not worthy of watching it more than once and promptly forgetting it except for playing a rather obscure trivia game. Director Juan Piquer Sim\\xc3\\xb3n is more widely known for his previous films \"Pod People\" (which MST3K deservedly mocked) and \"Peices\" (which is quite possibly the funnest bad movie ever made) <br /><br />Eye Candy: Kari Rose shows T&A <br /><br />My Grade: D+ <br /><br />DVD Extras: Merely a theatrical trailer for this movie',\n",
      "       b'(Honestly, Barbra, I know it\\'s you who\\'s klicking all those \"NO\"s on my review. 22 times?? How many people did you have to instruct to help you out here? Don\\'t you have anything better to do, like look at yourself in the mirror all day?)<br /><br />Steven Spielberg told Barbra that this was \"the best movie I\\'ve seen since \\'Citizen Kane\\'\". That pretty much says it all - and serves as a dire warning!<br /><br />What are the ingredients for a sure-fire cinematic disaster, and one that will haunt you, never letting you forget the tears of both laughter and pain? The ingredients: Barbra Streisand\\'s face, a musical, feminism, Barbra Streisand\\'s voice, Barbra Streisand directing, and an ultra-corny/idiotic premise.<br /><br />Hollywood is full of egomaniacs, this much we know. In fact, nearly everyone \\xc2\\x96 by definition \\xc2\\x96 has to be an egomaniac in Hollywood. Why would anyone want to act? For the \"art\"?!? Well, if you\\'re dumb enough to believe what they tell you in their carefully prepared interviews\\xc2\\x85 And Streisand has the biggest ego of them all! This is quite an achievement. To be surrounded by narcissistic cretins, and yet to manage to top them all \\xc2\\x96 remarkable.<br /><br />The movie, like all her \"solo\" endeavors, is an ego trip straight out of hell. Every scene Streisand is in is automatically ruined. Stillborn. But as it that weren\\'t enough, she sings a whole bunch of Streisandy songs \\xc2\\x96 you know, the kind that enabled the Mariah Careys, the Celine Dions, and the Whitney Hustons of this world to poison our precious air-waves for decades now. Just for that she deserves not one but 100 South Park episodes mocking her.<br /><br />The premise, Streisand dressing up as a man to study to become a rabbi, sounds like a zany ZAZ comedy. Apart from it being a clich\\xc3\\xa9, the obvious problem is that Streisand doesn\\'t look like a woman nor does she look like a man \\xc2\\x96 in fact I\\'m not even sure she\\'s human. The way she looks in this movie, well\\xc2\\x85 it cannot be described in words. E.T. looks like a high-school jock by comparison. She looks more alien than Michael Jackson in the year 2015. She looks HORRIBLE.<br /><br />The songs. They made me shiver. Particularly \"Papa Can You Hear Me Squeel Like A Demented Female Walrus In Heat?\" and \"Tomorrow Night I\\'ll Prepare the Sequel, YENTL 2: THE RETURN OF THE BITCH\".<br /><br />Did you know that Streisand considered having a nose-job early on in her career, but changed her mind when they told her her voice might change? Can you believe that? She should have done it! Killing two flies with one swipe, that\\'s what it would have been.<br /><br />If you\\'re interested in reading my biographies of Barbra Streisand and other Hollywood intellectuals, contact me by e-mail.<br /><br />SHOULD BARBRA STREISAND FINALLY GO INTO RETIREMENT? CLICK \"YES\" OR \"NO\".'],\n",
      "      dtype=object)>, <tf.Tensor: id=213, shape=(32,), dtype=int64, numpy=\n",
      "array([0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 1, 0, 0, 0, 1, 0, 0, 0])>)\n"
     ]
    }
   ],
   "source": [
    "for element in train_set.take(1):\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nnlm-en-dim50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = hub.load(\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1\")\n",
    "embeddings = embed([\"cat is on the mat\", \"dog is in the fog\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=396, shape=(2, 50), dtype=float32, numpy=\n",
       "array([[ 0.16589954,  0.0254965 ,  0.1574857 ,  0.17688066,  0.02911299,\n",
       "        -0.03092718,  0.19445257, -0.05709129, -0.08631689, -0.04391516,\n",
       "         0.13032274,  0.10905275, -0.08515751,  0.01056632, -0.17220995,\n",
       "        -0.17925954,  0.19556305,  0.0802278 , -0.03247919, -0.49176937,\n",
       "        -0.07767699, -0.03160921, -0.13952136,  0.05959712,  0.06858718,\n",
       "         0.22386682, -0.16653948,  0.19412343, -0.05491862,  0.10997339,\n",
       "        -0.15811177, -0.02576607, -0.07910853, -0.258499  , -0.04206644,\n",
       "        -0.20052543,  0.1705603 , -0.15314153,  0.0039225 , -0.28694248,\n",
       "         0.02468278,  0.11069503,  0.03733957,  0.01433943, -0.11048374,\n",
       "         0.11931834, -0.11552787, -0.11110869,  0.02384969, -0.07074881],\n",
       "       [ 0.1437864 ,  0.08291595,  0.10897306,  0.04464385, -0.03630389,\n",
       "        -0.12605834,  0.20263346,  0.12862863, -0.07873426, -0.01195358,\n",
       "         0.0020956 , -0.03080653, -0.08019945, -0.18797135, -0.11973457,\n",
       "        -0.26926652,  0.05157408, -0.15541205, -0.12221853, -0.27182642,\n",
       "         0.08750801, -0.05013347,  0.03012378,  0.20534228,  0.10000334,\n",
       "         0.18292566, -0.18280756,  0.0780353 ,  0.10936535, -0.10147726,\n",
       "        -0.19995196,  0.0398768 , -0.15377024, -0.1095404 , -0.18498933,\n",
       "        -0.15899731,  0.0558111 ,  0.15251887,  0.02046264, -0.25878936,\n",
       "        -0.13057052,  0.0782799 ,  0.04044291,  0.14456013,  0.00264394,\n",
       "         0.1399635 , -0.04803645, -0.17253871, -0.03153546,  0.09077   ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Weight and gradient histograms not supported for eagerexecution, setting `histogram_freq` to `0`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Weight and gradient histograms not supported for eagerexecution, setting `histogram_freq` to `0`.\n"
     ]
    }
   ],
   "source": [
    "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "model = keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1\",\n",
    "                   dtype=tf.string, input_shape=[], output_shape=[50]),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 50)                48190600  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               6528      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 48,197,257\n",
      "Trainable params: 6,657\n",
      "Non-trainable params: 48,190,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 52 steps\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.543404). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.543404). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/52 [..............................] - ETA: 30s - loss: 0.6005 - acc: 0.6875WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.277269). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.277269). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 24ms/step - loss: 0.5317 - acc: 0.7308\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5084 - acc: 0.7578\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5270 - acc: 0.7362\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5145 - acc: 0.7410\n",
      "Epoch 5/15\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5191 - acc: 0.7398\n",
      "Epoch 6/15\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4961 - acc: 0.7620\n",
      "Epoch 7/15\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5161 - acc: 0.7446\n",
      "Epoch 8/15\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5093 - acc: 0.7596\n",
      "Epoch 9/15\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5182 - acc: 0.7440\n",
      "Epoch 10/15\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4950 - acc: 0.7698\n",
      "Epoch 11/15\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5227 - acc: 0.7404\n",
      "Epoch 12/15\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5309 - acc: 0.7392\n",
      "Epoch 13/15\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5068 - acc: 0.7500\n",
      "Epoch 14/15\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.4894 - acc: 0.7692\n",
      "Epoch 15/15\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.5147 - acc: 0.7554\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set, steps_per_epoch=steps_per_epoch_train, epochs=num_epochs, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 12ms/step - loss: 0.5405 - acc: 0.7302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5405245767189906, 0.7301683]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set, steps=steps_per_epoch_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill 13518"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c7f95452a5b921cb\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c7f95452a5b921cb\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6008;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/fit  --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
